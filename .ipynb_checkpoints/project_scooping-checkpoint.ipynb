{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c88197",
   "metadata": {
    "id": "53c88197"
   },
   "source": [
    "# DSCI 521: Data Analysis and Interpretation <br> Term Project Phase 1: Scoping an analytics project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06276e19",
   "metadata": {
    "id": "06276e19"
   },
   "source": [
    "## Group members \n",
    "- Group member \n",
    "    - Name: Amira Bendjama\n",
    "    - Email: ab4745@drexel.edu\n",
    "- Group member \n",
    "    - Name: Thuy Hong Doan\n",
    "    - Email: td688@drexel.edu\n",
    "- Group member \n",
    "    - Name: Alsulami Meznah\n",
    "    - Email: mha54@drexel.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef10126",
   "metadata": {
    "id": "9ef10126"
   },
   "source": [
    "## Team members background:\n",
    "\n",
    "What areas/skills/domains does the team member presently identify with?\n",
    "Into which areas/skills/domains would the team member like to grow?\n",
    "\n",
    "- __Amira Bendjama__: is an Algerian Fulbrighter with a bachelor’s in computer science, and a master’s in networks and distributed systems. Her skill set varies from different programming languages, to problem solving and critical thinking. She worked with Youtube API V3 to retrieve dataset for [Valorant comments on Youtube](https://github.com/amira-bendjama/VALORANT-COMMENTS). \n",
    "\n",
    "- __Alsulami Meznah__: is a graduate student in Data Science. She majored in bachelor's degree was in Information Systems.  She has a good background on Java, Visual Basic, SQL. She looks forward to improving my skills and learning more about Python and R.\n",
    "\n",
    "- __Thuy Hong Doan__: graduated with a bachelor of business administration in Computer Information Systems. Her skill set varies from different programming languages, to analytical and problem solving skills. She worked with HTML, CSS, SQL, JavaScript, and Python. She plans to use her previous coding experience and understanding of data structure to help successfully complete this project.\n",
    "\n",
    "### Growth area \n",
    "\n",
    "We are looking to take on a project that presents real world data analysis challenges in order to align our skills with the type of work we would undertake in the professional world. Analyzing dataset is particularly challenging because of different steps we need to take before actualy analysis the dataset such cleaning the dataset, checking the correcteness, and thus is a good way to learn about data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151eb4bf",
   "metadata": {
    "id": "151eb4bf"
   },
   "source": [
    "## Topic summary \n",
    "\n",
    "YouTube is one of the leading video sharing and social media platform in the world. Thus, It had a huge impact on changing the marketing startegies by video promotion or sponsoring independent Youtubers, with its captivating features such as the recommendation page, and trending page. However, the later doesn’t have a clear indication of what makes a Youtube video trending. Hence, the speculation on what makes a video trending such as [Researching The Trending Tab (BTS)](https://www.youtube.com/watch?v=sEvtpj-uChA&ab_channel=Coffeezilla), [What Is YouTube Trending And How It Works](https://www.notion.so/project-scooping-427deb3f9cbc4c32949c17248bdc0a30#04a09cb6fee248398f38d2fa43a72052). The goal of the project is to perform EDA analysis on the dataset to find the patterns among trending videos and develop a classification model to attribute the factor that affects how popular a Youtube video will be. Those insights might be used by Youtube channels owned by tradational companies that seek to break into the new marketing field, or they can be used by individual Youtubers that seek to increase the popularity of their videos, without effecting their content creation. This project will relay on [dataset](https://www.kaggle.com/datasets/rsrishav/youtube-trending-video-dataset) from Kaggle which was collected using the Youtube API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b155c0",
   "metadata": {
    "id": "a1b155c0"
   },
   "source": [
    "## Term Project Phase 1: details \n",
    "\n",
    "__What is our dataset?__\n",
    "\n",
    "Dataset is collected using Youtube API, for different regions. However, the project will focus on United states' dataset. The data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count, category.\n",
    "\n",
    "__What is the availability of relevant pre-processed data?__\n",
    "\n",
    "The dataset is available for the public in [Kaggle](https://www.kaggle.com/datasets/rsrishav/youtube-trending-video-dataset). \n",
    "\n",
    "__What will the analysis to do, who/what it will support?__ \n",
    "\n",
    "The EDA analysis on the dataset to find the patterns among trending videos and develop a classification model to find the factors. The questions we are trying to solve are: \n",
    "1. what are top most trending Categories? \n",
    "2. what is the impact of Likes,Dislikes and Comments.\n",
    "3. what is the most used words for titles, video description, tags?\n",
    "\n",
    "__Who would be interested in the data analysis?__\n",
    "- Adverstiser to sponsor Youtube videos that have the potenial to be trending\n",
    "- Youtube channels owned by companies that want to keep up with the trends for better preforming product ads. \n",
    "- Independent Youtubers who wants to make trending videos\n",
    "- Researchers to derive insight about behavior from Youtube trends and marketing startegies \n",
    "\n",
    "__Limitations__\n",
    "\n",
    "- The dataset is limited to several months and only 200 videos per day, and hence it could add some bias on the predictions. \n",
    "- World events that are relevent to only several months can effect the prediction greatly in a small dataset.\n",
    "- Absence of duration column in dataset, which is considered one of the factors to impact the trending videos.\n",
    "\n",
    "__Potential solutions__ \n",
    "- The results can be improved by extending the data collection to few years back, \n",
    "- Improving  the predection to ignore the irrelevent events. \n",
    "- Adding the duration column to the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1736d83",
   "metadata": {
    "id": "e1736d83"
   },
   "source": [
    "__How the analysis might fit into an application or investigation?__ \n",
    "\n",
    "\n",
    "__Selection data for continued analysis, including justification:__ \n",
    "\n",
    "\n",
    "__How our analysis might be completed and disseminated?__\n",
    "\n",
    "The duration of the project won't allow to compare different classification models, \n",
    "\n",
    "\n",
    "\n",
    "### Potential Software used \n",
    "- Juypter notebook \n",
    "\n",
    "### Hardware used \n",
    "- Acer processor i5 RAM 8GB\n",
    "- Hp processor i7 RAM 8GB\n",
    "- Macbook Pro processor i5 RAM 8GB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f48f7",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eeef509",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires dateutil>=2.7; you have 2.2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:208\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    204\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 208\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache()\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:204\u001b[0m, in \u001b[0;36m_check_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    202\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Matplotlib requires dateutil>=2.7; you have 2.2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "US_category_id = pd.read_json('data/US_category_id.json')\n",
    "trending_youtube = pd.read_csv('data/US_youtube_trending_data.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110955eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_category_id.shape\n",
    "trending_youtube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e987a",
   "metadata": {},
   "source": [
    "#### Some of the columns are redundant for our analysis so we will drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube.drop(['video_id','thumbnail_link', 'description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66690e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b7747",
   "metadata": {},
   "source": [
    "#### Trending date and publishedAt columns have object data type which needs to changed as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube[['publishedAt', 'trending_date']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75592a5e",
   "metadata": {},
   "source": [
    "#### For the trending date column, we need some reformatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trending_youtube['trending_date'] = pd.to_datetime(trending_youtube['trending_date'], format = \"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a6878",
   "metadata": {},
   "source": [
    "#### The publishedAt column converted with the astype function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e946f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube['publishedAt'] = trending_youtube['publishedAt'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube[['publishedAt', 'trending_date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube[['trending_date','publishedAt']].dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05a7ac",
   "metadata": {},
   "source": [
    "The difference between the time a video is published and its trending time might be a useful piece of information for the analysis. Since both columns have datetime data type, we can easily calculate the time difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube['time_diff'] = trending_youtube['trending_date'] - trending_youtube['publishedAt']\n",
    "trending_youtube['time_diff'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491a25f",
   "metadata": {},
   "source": [
    "most of the videos uploaded by different channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065003dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube.channelTitle.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a721f84",
   "metadata": {},
   "source": [
    "The data type of the time_diff column is timedelta. We need to convert it to a numerical variable to plot its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube['time_diff_hour'] = trending_youtube['time_diff'] / pd.Timedelta('1 hour')\n",
    "trending_youtube['time_diff_hour'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube['time_diff_hour'].mean() / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8f3c6",
   "metadata": {},
   "source": [
    "When we take the mean and divide by 24, we get the same value as the mean of the time_diff column.\n",
    "One type of visualization that gives us an overview of the distribution is the box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ca69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=trending_youtube, y='time_diff_hour')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b96fca",
   "metadata": {},
   "source": [
    "eliminate the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trending_youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396aa58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trending_youtube[trending_youtube.time_diff_hour > 600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trending_youtube[trending_youtube.time_diff_hour <= 600])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112f93e",
   "metadata": {},
   "source": [
    "The displot function of Seaborn to create a histogram as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de11870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=trending_youtube, x='time_diff_hour', kind='hist',aspect=1.5, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c531a",
   "metadata": {},
   "source": [
    "compare the average views of trending videos published by these channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube['views_mil'] = trending_youtube['view_count'] / 1000000\n",
    "trending_youtube[['channelId','views_mil']].groupby('channelId')\\\n",
    ".agg(['mean','count'])\\\n",
    ".sort_values(by=('views_mil','count'), ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5392fe6",
   "metadata": {},
   "source": [
    "The number of trending videos changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = trending_youtube[['trending_date']].value_counts().reset_index()\\\n",
    ".sort_values(by='trending_date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e173686",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb5025",
   "metadata": {},
   "source": [
    "Generate a line plot based on the daily dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=daily, x='trending_date', y=0,\n",
    "kind='line', aspect=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e047381-842b-47ac-977b-05f200d6f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3284642-5cbb-465b-a38c-90b549a5a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary for json file provided for category and category id\n",
    "category_dict = {}\n",
    "for i in US_category_id['items']:\n",
    "    category_dict[i['id']] = i['snippet']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c750259-e61f-4093-87f3-0ec6b8bd835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the category id with category actual name \n",
    "def replace_categoryid(df):\n",
    "    if str(df) in category_dict:\n",
    "        return category_dict[str(df)]\n",
    "    \n",
    "trending_youtube['category'] = trending_youtube['categoryId'].apply(replace_categoryid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a38d78-422a-4f26-a694-6fd0dce1a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_youtube.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b19909-6402-4d37-87ee-fc886ac93814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby category\n",
    "category_group = trending_youtube.groupby(by = trending_youtube['category']).sum()\n",
    "category_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85431c-6ec1-423b-ba41-0551641b65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the 5 categories with largest view count, likes, dislikes, comment_count}\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "list = ['view_count','likes','dislikes','comment_count']\n",
    "\n",
    "for i in range(0,4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    x = category_group[list[i]].nlargest(5).index\n",
    "    y = category_group[list[i]].nlargest(5)\n",
    "    sns.barplot(x = x,y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751f13e-0c18-4c11-93d0-881d98dd768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the 5 Categories with smallest view count, likes, dislikes, comment_count \n",
    "plt.figure(figsize = (20,8))\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "list = ['view_count','likes','dislikes','comment_count']\n",
    "\n",
    "for i in range(0,4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    x = category_group[list[i]].nsmallest(5).index\n",
    "    y = category_group[list[i]].nsmallest(5)\n",
    "    sns.barplot(x = x,y = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6fe2a-e119-4b52-82c0-4f2218f6d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
